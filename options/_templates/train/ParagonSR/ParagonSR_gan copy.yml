# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
#########################################################################################
# General Settings
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#top-level-options
#########################################################################################
name: 4xParagonSR_S_GAN
scale: 4  # 1, 2, 3, 4, 8
use_amp: true  # Speed up training and reduce VRAM usage. NVIDIA only.
amp_bf16: true  # Use bf16 instead of fp16 for AMP, RTX 3000 series or newer only. Only recommended if fp16 doesn't work.
use_channels_last: false  # Enable channels last memory format while using AMP. Reduces VRAM and speeds up training for most architectures, but some architectures are slower with channels last.
fast_matmul: false  # Trade precision for performance.
num_gpu: auto
# manual_seed: 1024  # Random seed for training, useful for removing randomness when testing the effect of different settings.


########################################################################################################################
# Dataset and Dataloader Settings
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#dataset-options-datasets-train-and-datasets-val
########################################################################################################################
datasets:
  # Settings for the training dataset.
  train:
    name: Train Dataset
    type: pairedimagedataset
    # Path to the HR (high res) images in your training dataset. Specify one or multiple folders, separated by commas.
    dataroot_gt: [
      /home/phips/Documents/dataset/cc0/hr
    ]
    # Path to the LR (low res) images in your training dataset. Specify one or multiple folders, separated by commas.
    dataroot_lq: [
      /home/phips/Documents/dataset/cc0/lr_pretrain_x4
    ]
    # meta_info: data/meta_info/dataset1.txt


    lq_size: 64  # During training, a square of this size is cropped from LR images. Larger is usually better but uses more VRAM. Previously gt_size, use lq_size = gt_size / scale to convert. Use multiple of 8 for best performance with AMP.
    use_hflip: true  # Randomly flip the images horizontally.
    use_rot: true  # Randomly rotate the images.

    num_worker_per_gpu: 8
    batch_size_per_gpu: 4  # Increasing stabilizes training but with diminishing returns. Use multiple of 8 for best performance with AMP.
    accum_iter: 1  # paper: 8  # Using values larger than 1 simulates higher batch size by trading performance for reduced VRAM usage. If accum_iter = 4 and batch_size_per_gpu = 6 then effective batch size = 4 * 6 = 24 but performance may be as much as 4 times as slow.
  # Settings for your validation dataset (optional). These settings will
  # be ignored if val_enabled is false in the Validation section below.
  val:
    name: Val Dataset
    type: pairedimagedataset
    dataroot_gt: [
      /home/phips/Documents/dataset/cc0/val_hr
    ]
    dataroot_lq: [
      /home/phips/Documents/dataset/cc0/val_x4
    ]

#####################################################################
# Network Settings
# https://trainner-redux.readthedocs.io/en/latest/arch_reference.html
#####################################################################
# Generator model settings
network_g:
  type: paragonsr_s  # ParagonSR_S variant

# Discriminator model settings
network_d:
  type: dunet  # dunet, metagan2, unetdiscriminatorsn

#########################################################################################
# Pretrain and Resume Paths
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#path-options-path
#########################################################################################
path:
  pretrain_network_g: experiments/4x_ParagonSR_S/models/4xParagonSR_S_pretrain.safetensors
  param_key_g: ~
  strict_load_g: true    # Disable strict loading to partially load a pretrain model with a different scale
  resume_state: ~

###########################################################################################
# Training Settings
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#train-options-train
###########################################################################################
train:
  ema_decay: 0.9999  # Very high EMA decay for stable fine-tuning
  grad_clip: true     # Enable gradient clipping (essential for stability)

  optim_g:
    type: AdamW
    lr: 5e-6          # Reduced LR for stability
    weight_decay: 0.02  # Slight weight decay for regularization
    betas: [0.85, 0.98]    # More aggressive beta1 for faster adaptation
  optim_d:
    type: AdamW
    lr: 5e-6          # Needs to keep up
    weight_decay: 0
    betas: [0.85, 0.98]  # Match generator for balance

  scheduler:
    type: MultiStepLR
    milestones: [125000, 200000, 225000, 237500]
    gamma: 0.5

  total_iter: 250000  # Total number of iterations.
  warmup_iter: 2000  # Gradually ramp up learning rates until this iteration, to stabilize early training. Use -1 to disable.

  # Losses - for any loss set the loss_weight to 0 to disable it.
  # https://trainner-redux.readthedocs.io/en/latest/loss_reference.html
  losses:
    # === FOUNDATIONAL LOSSES ===

    # Pixel/Content preservation (reduced from typical weights)
    - type: l1loss
      loss_weight: 0.3   # Increased for better content preservation during GAN training
      reduction: mean

    # SSIM-based structural loss (good for perceptual quality)
    - type: mssimloss
      loss_weight: 0.25

    # === PERCEPTUAL LOSSES (Main focus for fine-tuning) ===

    # Standard perceptual loss (VGG-based)
    - type: perceptualloss
      criterion: charbonnier
      loss_weight: 1.0

    # Enhanced color perception
    - type: hsluvloss
      criterion: charbonnier
      loss_weight: 0.8    # Moderate weight for good color reproduction

    # Structural similarity
    - type: cosimloss
      loss_weight: 0.6

    # === ADVANCED PERCEPTUAL LOSSES ===

    # Contextual loss for better texture preservation
    - type: contextualloss
      loss_weight: 0.2

    - type: adistsloss      # Better than standard DISTS
      loss_weight: 0.15

    # Focal Frequency Loss - Great for sharp details and edges
    - type: ffloss
      loss_weight: 0.03

    - type: gradientvarianceloss
      loss_weight: 0.05

    # === GAN LOSS (Optimized for stability + effectiveness) ===

    - type: ganloss
      gan_type: multiscaler3gan
      loss_weight: 0.025    #
      r1_weight: 3.0       # R1 penalty
      r2_weight: 3.0       # R2 penalty

    # === ANTI-PATTERN LOSS (Critical for PixelShuffle) ===
    - type: checkerboardloss
      loss_weight: 0.1  # Strong weight to prevent checkerboard patterns

  # Mix of Augmentations (MoA)
  use_moa: false  # Whether to enable mixture of augmentations, which augments the dataset on the fly to create more variety and help the model generalize.
  moa_augs: ['none', 'mixup', 'cutmix', 'resizemix', 'cutblur']  # The list of augmentations to choose from, only one is selected per iteration.
  moa_probs: [0.4, 0.084, 0.084, 0.084, 0.348]  # The probability each augmentation in moa_augs will be applied. Total should add up to 1.
  moa_debug: false  # Save images before and after augment to debug/moa folder inside of the root training directory.
  moa_debug_limit: 100  # The max number of iterations to save augmentation images for.

##############################################################################################
# Validation
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#validation-options-val
##############################################################################################
val:
  val_enabled: true  # Whether to enable validations. If disabled, all validation settings below are ignored.
  val_freq: 1000  # How often to run validations, in iterations.
  save_img: true  # Whether to save the validation images during validation, in the experiments/<name>/visualization folder.
  tile_size: 0  # Tile size of input, reduce VRAM usage but slower inference. 0 to disable.
  tile_overlap: 8  # Number of pixels to overlap tiles by, larger is slower but reduces tile seams.

  metrics_enabled: true  # Whether to run metrics calculations during validation.
  metrics:
    topiq:
      type: calculate_topiq
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 4  # Whether to crop border during validation.
      test_y_channel: false  # Whether to convert to Y(CbCr) for validation.
    lpips:
      type: calculate_lpips
      better: lower
    dists:
      type: calculate_dists
      better: lower

##############################################################################################
# Logging
# https://trainner-redux.readthedocs.io/en/latest/config_reference.html#logging-options-logger
##############################################################################################
logger:
  print_freq: 100
  save_checkpoint_freq: 1000
  save_checkpoint_format: safetensors
  use_tb_logger: true
